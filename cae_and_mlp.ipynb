{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AnZbxxapz_XQ"
      },
      "source": [
        "## CAE for feature extraction and MLP for recognition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4H5LjGlpA8G6"
      },
      "outputs": [],
      "source": [
        "from keras.datasets import cifar10\n",
        "from keras.models import Model, Sequential\n",
        "from keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2D, Flatten, BatchNormalization, Dropout, Reshape\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from keras.callbacks import EarlyStopping\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras import backend as K"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2WhIFZ4u0JTJ"
      },
      "source": [
        "### CIFAR-10 dataset used"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a7iDGz9vBAcr",
        "outputId": "9b745318-7388-4880-c2c2-864e47ffeb0a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170498071/170498071 [==============================] - 4s 0us/step\n"
          ]
        }
      ],
      "source": [
        "# Load CIFAR-10 dataset\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wKHIrpen0RPw"
      },
      "source": [
        "### Defining the models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vGTmlvxzCLS0",
        "outputId": "5ad1f545-1401-40d4-d5ea-9287c333bbca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1250/1250 [==============================] - 4s 2ms/step\n",
            "313/313 [==============================] - 1s 2ms/step\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 128)               32896     \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 128)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 64)                8256      \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 10)                650       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 41802 (163.29 KB)\n",
            "Trainable params: 41802 (163.29 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# Normalize and convert to float32\n",
        "x_train = x_train.astype('float32') / 255.0\n",
        "x_test = x_test.astype('float32') / 255.0\n",
        "\n",
        "# Define the input shape\n",
        "input_img = Input(shape=(32, 32, 3))\n",
        "\n",
        "# Encoder part of the CAE\n",
        "x = Conv2D(64, (3, 3), activation='relu', padding='same')(input_img)\n",
        "x = MaxPooling2D((2, 2))(x)\n",
        "x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
        "x = MaxPooling2D((2, 2))(x)\n",
        "x = Conv2D(16, (3, 3), activation='relu', padding='same')(x)\n",
        "encoded = MaxPooling2D((2, 2))(x)\n",
        "\n",
        "# Flatten the encoded output for MLP\n",
        "flatten = Flatten()(encoded)\n",
        "\n",
        "# Create a model for encoding features\n",
        "encoder_model = Model(input_img, flatten)\n",
        "\n",
        "# Obtain encoded features for training and validation sets\n",
        "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=42)\n",
        "flatten_train_np = encoder_model.predict(x_train)\n",
        "flatten_val_np = encoder_model.predict(x_val)\n",
        "\n",
        "# MLP for recognition\n",
        "mlp = Sequential([\n",
        "    Dense(128, activation='relu', input_shape=(flatten_train_np.shape[1],)),\n",
        "    Dropout(0.5),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile the MLP\n",
        "mlp.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "mlp.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i4KGVnhN0aRs"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EW11pOwVCPos",
        "outputId": "1674467f-7bf0-4f85-b192-3fb46c3b2c0e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "800/800 [==============================] - 6s 4ms/step - loss: 2.1288 - accuracy: 0.1894 - val_loss: 1.9936 - val_accuracy: 0.2756\n",
            "Epoch 2/100\n",
            "800/800 [==============================] - 2s 3ms/step - loss: 1.9963 - accuracy: 0.2497 - val_loss: 1.8955 - val_accuracy: 0.3006\n",
            "Epoch 3/100\n",
            "800/800 [==============================] - 2s 3ms/step - loss: 1.9241 - accuracy: 0.2837 - val_loss: 1.8131 - val_accuracy: 0.3473\n",
            "Epoch 4/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 1.8729 - accuracy: 0.3079 - val_loss: 1.7707 - val_accuracy: 0.3588\n",
            "Epoch 5/100\n",
            "800/800 [==============================] - 2s 3ms/step - loss: 1.8414 - accuracy: 0.3216 - val_loss: 1.7340 - val_accuracy: 0.3786\n",
            "Epoch 6/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 1.8193 - accuracy: 0.3288 - val_loss: 1.7071 - val_accuracy: 0.3873\n",
            "Epoch 7/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 1.7994 - accuracy: 0.3421 - val_loss: 1.7080 - val_accuracy: 0.3936\n",
            "Epoch 8/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 1.7865 - accuracy: 0.3485 - val_loss: 1.6698 - val_accuracy: 0.3938\n",
            "Epoch 9/100\n",
            "800/800 [==============================] - 2s 3ms/step - loss: 1.7749 - accuracy: 0.3517 - val_loss: 1.6784 - val_accuracy: 0.3942\n",
            "Epoch 10/100\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 1.7619 - accuracy: 0.3562 - val_loss: 1.6610 - val_accuracy: 0.3986\n",
            "Epoch 11/100\n",
            "800/800 [==============================] - 2s 3ms/step - loss: 1.7553 - accuracy: 0.3593 - val_loss: 1.6388 - val_accuracy: 0.4104\n",
            "Epoch 12/100\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 1.7496 - accuracy: 0.3661 - val_loss: 1.6372 - val_accuracy: 0.4117\n",
            "Epoch 13/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 1.7382 - accuracy: 0.3694 - val_loss: 1.6260 - val_accuracy: 0.4129\n",
            "Epoch 14/100\n",
            "800/800 [==============================] - 2s 3ms/step - loss: 1.7355 - accuracy: 0.3674 - val_loss: 1.6309 - val_accuracy: 0.4131\n",
            "Epoch 15/100\n",
            "800/800 [==============================] - 2s 3ms/step - loss: 1.7274 - accuracy: 0.3747 - val_loss: 1.6113 - val_accuracy: 0.4171\n",
            "Epoch 16/100\n",
            "800/800 [==============================] - 2s 3ms/step - loss: 1.7240 - accuracy: 0.3750 - val_loss: 1.6138 - val_accuracy: 0.4181\n",
            "Epoch 17/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 1.7186 - accuracy: 0.3738 - val_loss: 1.6043 - val_accuracy: 0.4256\n",
            "Epoch 18/100\n",
            "800/800 [==============================] - 2s 3ms/step - loss: 1.7170 - accuracy: 0.3826 - val_loss: 1.6039 - val_accuracy: 0.4275\n",
            "Epoch 19/100\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 1.7125 - accuracy: 0.3808 - val_loss: 1.5947 - val_accuracy: 0.4248\n",
            "Epoch 20/100\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 1.7090 - accuracy: 0.3826 - val_loss: 1.5844 - val_accuracy: 0.4385\n",
            "Epoch 21/100\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 1.7080 - accuracy: 0.3832 - val_loss: 1.5966 - val_accuracy: 0.4358\n",
            "Epoch 22/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 1.7035 - accuracy: 0.3835 - val_loss: 1.5793 - val_accuracy: 0.4407\n",
            "Epoch 23/100\n",
            "800/800 [==============================] - 2s 3ms/step - loss: 1.7020 - accuracy: 0.3862 - val_loss: 1.5824 - val_accuracy: 0.4324\n",
            "Epoch 24/100\n",
            "800/800 [==============================] - 2s 3ms/step - loss: 1.6987 - accuracy: 0.3875 - val_loss: 1.5928 - val_accuracy: 0.4328\n",
            "Epoch 25/100\n",
            "800/800 [==============================] - 2s 3ms/step - loss: 1.6919 - accuracy: 0.3915 - val_loss: 1.5774 - val_accuracy: 0.4324\n",
            "Epoch 26/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 1.6985 - accuracy: 0.3893 - val_loss: 1.5803 - val_accuracy: 0.4382\n",
            "Epoch 27/100\n",
            "800/800 [==============================] - 2s 3ms/step - loss: 1.6898 - accuracy: 0.3895 - val_loss: 1.5855 - val_accuracy: 0.4383\n",
            "Epoch 28/100\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 1.6856 - accuracy: 0.3952 - val_loss: 1.5670 - val_accuracy: 0.4347\n",
            "Epoch 29/100\n",
            "800/800 [==============================] - 2s 3ms/step - loss: 1.6866 - accuracy: 0.3936 - val_loss: 1.5613 - val_accuracy: 0.4436\n",
            "Epoch 30/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 1.6853 - accuracy: 0.3932 - val_loss: 1.5798 - val_accuracy: 0.4413\n",
            "Epoch 31/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 1.6827 - accuracy: 0.3954 - val_loss: 1.5832 - val_accuracy: 0.4322\n",
            "Epoch 32/100\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 1.6798 - accuracy: 0.3980 - val_loss: 1.5665 - val_accuracy: 0.4438\n",
            "Epoch 33/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 1.6763 - accuracy: 0.3945 - val_loss: 1.5614 - val_accuracy: 0.4445\n",
            "Epoch 34/100\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 1.6828 - accuracy: 0.3954 - val_loss: 1.5667 - val_accuracy: 0.4455\n",
            "Epoch 35/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 1.6777 - accuracy: 0.3976 - val_loss: 1.5701 - val_accuracy: 0.4459\n",
            "Epoch 36/100\n",
            "800/800 [==============================] - 2s 3ms/step - loss: 1.6726 - accuracy: 0.3975 - val_loss: 1.5753 - val_accuracy: 0.4364\n",
            "Epoch 37/100\n",
            "800/800 [==============================] - 2s 3ms/step - loss: 1.6722 - accuracy: 0.4008 - val_loss: 1.5619 - val_accuracy: 0.4376\n",
            "Epoch 38/100\n",
            "800/800 [==============================] - 2s 3ms/step - loss: 1.6698 - accuracy: 0.3998 - val_loss: 1.5571 - val_accuracy: 0.4411\n",
            "Epoch 39/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 1.6735 - accuracy: 0.4002 - val_loss: 1.5551 - val_accuracy: 0.4455\n",
            "Epoch 40/100\n",
            "800/800 [==============================] - 2s 3ms/step - loss: 1.6730 - accuracy: 0.4008 - val_loss: 1.5459 - val_accuracy: 0.4495\n",
            "Epoch 41/100\n",
            "800/800 [==============================] - 2s 3ms/step - loss: 1.6694 - accuracy: 0.3988 - val_loss: 1.5483 - val_accuracy: 0.4497\n",
            "Epoch 42/100\n",
            "800/800 [==============================] - 2s 3ms/step - loss: 1.6651 - accuracy: 0.4014 - val_loss: 1.5611 - val_accuracy: 0.4520\n",
            "Epoch 43/100\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 1.6678 - accuracy: 0.4053 - val_loss: 1.5796 - val_accuracy: 0.4405\n",
            "Epoch 44/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 1.6616 - accuracy: 0.4040 - val_loss: 1.5601 - val_accuracy: 0.4450\n",
            "Epoch 45/100\n",
            "800/800 [==============================] - 2s 3ms/step - loss: 1.6625 - accuracy: 0.4035 - val_loss: 1.5554 - val_accuracy: 0.4484\n",
            "Epoch 46/100\n",
            "800/800 [==============================] - 2s 3ms/step - loss: 1.6655 - accuracy: 0.4017 - val_loss: 1.5606 - val_accuracy: 0.4345\n",
            "Epoch 47/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 1.6610 - accuracy: 0.4036 - val_loss: 1.5665 - val_accuracy: 0.4488\n",
            "Epoch 48/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 1.6552 - accuracy: 0.4076 - val_loss: 1.5397 - val_accuracy: 0.4518\n",
            "Epoch 49/100\n",
            "800/800 [==============================] - 2s 3ms/step - loss: 1.6626 - accuracy: 0.4040 - val_loss: 1.5391 - val_accuracy: 0.4585\n",
            "Epoch 50/100\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 1.6607 - accuracy: 0.4058 - val_loss: 1.5458 - val_accuracy: 0.4520\n",
            "Epoch 51/100\n",
            "800/800 [==============================] - 2s 3ms/step - loss: 1.6549 - accuracy: 0.4054 - val_loss: 1.5420 - val_accuracy: 0.4492\n",
            "Epoch 52/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 1.6606 - accuracy: 0.4037 - val_loss: 1.5429 - val_accuracy: 0.4546\n",
            "Epoch 53/100\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 1.6518 - accuracy: 0.4071 - val_loss: 1.5481 - val_accuracy: 0.4507\n",
            "Epoch 54/100\n",
            "800/800 [==============================] - 2s 3ms/step - loss: 1.6515 - accuracy: 0.4085 - val_loss: 1.5461 - val_accuracy: 0.4578\n",
            "Epoch 55/100\n",
            "800/800 [==============================] - 2s 3ms/step - loss: 1.6496 - accuracy: 0.4071 - val_loss: 1.5449 - val_accuracy: 0.4567\n",
            "Epoch 56/100\n",
            "800/800 [==============================] - 2s 3ms/step - loss: 1.6527 - accuracy: 0.4076 - val_loss: 1.5364 - val_accuracy: 0.4594\n",
            "Epoch 57/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 1.6527 - accuracy: 0.4064 - val_loss: 1.5361 - val_accuracy: 0.4546\n",
            "Epoch 58/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 1.6578 - accuracy: 0.4052 - val_loss: 1.5405 - val_accuracy: 0.4524\n",
            "Epoch 59/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 1.6507 - accuracy: 0.4113 - val_loss: 1.5477 - val_accuracy: 0.4512\n",
            "Epoch 60/100\n",
            "800/800 [==============================] - 2s 3ms/step - loss: 1.6481 - accuracy: 0.4102 - val_loss: 1.5496 - val_accuracy: 0.4511\n",
            "Epoch 61/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 1.6475 - accuracy: 0.4112 - val_loss: 1.5379 - val_accuracy: 0.4565\n",
            "Epoch 62/100\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 1.6475 - accuracy: 0.4103 - val_loss: 1.5381 - val_accuracy: 0.4534\n",
            "Epoch 63/100\n",
            "800/800 [==============================] - 2s 3ms/step - loss: 1.6462 - accuracy: 0.4099 - val_loss: 1.5459 - val_accuracy: 0.4607\n",
            "Epoch 64/100\n",
            "800/800 [==============================] - 2s 3ms/step - loss: 1.6448 - accuracy: 0.4133 - val_loss: 1.5466 - val_accuracy: 0.4574\n",
            "Epoch 65/100\n",
            "800/800 [==============================] - 2s 3ms/step - loss: 1.6423 - accuracy: 0.4152 - val_loss: 1.5392 - val_accuracy: 0.4537\n",
            "Epoch 66/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 1.6500 - accuracy: 0.4073 - val_loss: 1.5486 - val_accuracy: 0.4548\n",
            "Epoch 67/100\n",
            "800/800 [==============================] - 2s 3ms/step - loss: 1.6482 - accuracy: 0.4115 - val_loss: 1.5355 - val_accuracy: 0.4621\n",
            "Epoch 68/100\n",
            "800/800 [==============================] - 2s 3ms/step - loss: 1.6478 - accuracy: 0.4125 - val_loss: 1.5535 - val_accuracy: 0.4542\n",
            "Epoch 69/100\n",
            "800/800 [==============================] - 2s 3ms/step - loss: 1.6479 - accuracy: 0.4144 - val_loss: 1.5388 - val_accuracy: 0.4551\n",
            "Epoch 70/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 1.6419 - accuracy: 0.4107 - val_loss: 1.5286 - val_accuracy: 0.4587\n",
            "Epoch 71/100\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 1.6412 - accuracy: 0.4133 - val_loss: 1.5329 - val_accuracy: 0.4541\n",
            "Epoch 72/100\n",
            "800/800 [==============================] - 2s 3ms/step - loss: 1.6395 - accuracy: 0.4157 - val_loss: 1.5414 - val_accuracy: 0.4554\n",
            "Epoch 73/100\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 1.6452 - accuracy: 0.4113 - val_loss: 1.5300 - val_accuracy: 0.4589\n",
            "Epoch 74/100\n",
            "800/800 [==============================] - 2s 3ms/step - loss: 1.6458 - accuracy: 0.4123 - val_loss: 1.5293 - val_accuracy: 0.4542\n",
            "Epoch 75/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 1.6445 - accuracy: 0.4125 - val_loss: 1.5237 - val_accuracy: 0.4595\n",
            "Epoch 76/100\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 1.6381 - accuracy: 0.4150 - val_loss: 1.5314 - val_accuracy: 0.4529\n",
            "Epoch 77/100\n",
            "800/800 [==============================] - 2s 3ms/step - loss: 1.6394 - accuracy: 0.4153 - val_loss: 1.5326 - val_accuracy: 0.4602\n",
            "Epoch 78/100\n",
            "800/800 [==============================] - 2s 3ms/step - loss: 1.6380 - accuracy: 0.4142 - val_loss: 1.5340 - val_accuracy: 0.4593\n",
            "Epoch 79/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 1.6410 - accuracy: 0.4163 - val_loss: 1.5404 - val_accuracy: 0.4483\n",
            "Epoch 80/100\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 1.6351 - accuracy: 0.4177 - val_loss: 1.5274 - val_accuracy: 0.4616\n",
            "Epoch 81/100\n",
            "800/800 [==============================] - 3s 3ms/step - loss: 1.6370 - accuracy: 0.4187 - val_loss: 1.5356 - val_accuracy: 0.4568\n",
            "Epoch 82/100\n",
            "800/800 [==============================] - 2s 3ms/step - loss: 1.6392 - accuracy: 0.4148 - val_loss: 1.5335 - val_accuracy: 0.4510\n",
            "Epoch 83/100\n",
            "800/800 [==============================] - 2s 3ms/step - loss: 1.6366 - accuracy: 0.4148 - val_loss: 1.5271 - val_accuracy: 0.4594\n",
            "Epoch 84/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 1.6372 - accuracy: 0.4158 - val_loss: 1.5331 - val_accuracy: 0.4610\n",
            "Epoch 85/100\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 1.6300 - accuracy: 0.4191 - val_loss: 1.5260 - val_accuracy: 0.4608\n"
          ]
        }
      ],
      "source": [
        "# Train the MLP on the encoded features\n",
        "early_stopping_monitor = EarlyStopping(monitor='val_loss', patience=10, verbose=0, mode='min')\n",
        "mlp_history = mlp.fit(flatten_train_np, y_train,\n",
        "                      epochs=100,\n",
        "                      batch_size=50,\n",
        "                      validation_data=(flatten_val_np, y_val),\n",
        "                      callbacks=[early_stopping_monitor])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aSF8IkyLA0y4",
        "outputId": "a0053d3c-bb1a-43ff-cf6f-ce1490044ea8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 32, 32, 64)        1792      \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 16, 16, 64)        0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 16, 16, 32)        18464     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPoolin  (None, 8, 8, 32)          0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 8, 8, 16)          4624      \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPoolin  (None, 4, 4, 16)          0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 256)               0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 256)               65792     \n",
            "                                                                 \n",
            " reshape (Reshape)           (None, 4, 4, 16)          0         \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 4, 4, 16)          2320      \n",
            "                                                                 \n",
            " up_sampling2d (UpSampling2  (None, 8, 8, 16)          0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 8, 8, 32)          4640      \n",
            "                                                                 \n",
            " up_sampling2d_1 (UpSamplin  (None, 16, 16, 32)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 16, 16, 64)        18496     \n",
            "                                                                 \n",
            " up_sampling2d_2 (UpSamplin  (None, 32, 32, 64)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_6 (Conv2D)           (None, 32, 32, 3)         1731      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 117859 (460.39 KB)\n",
            "Trainable params: 117859 (460.39 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# Define the CAE model\n",
        "decoded = Dense(256, activation='relu')(flatten)\n",
        "decoded = Reshape((4, 4, 16))(decoded)\n",
        "decoded = Conv2D(16, (3, 3), activation='relu', padding='same')(decoded)\n",
        "decoded = UpSampling2D((2, 2))(decoded)\n",
        "decoded = Conv2D(32, (3, 3), activation='relu', padding='same')(decoded)\n",
        "decoded = UpSampling2D((2, 2))(decoded)\n",
        "decoded = Conv2D(64, (3, 3), activation='relu', padding='same')(decoded)\n",
        "decoded = UpSampling2D((2, 2))(decoded)\n",
        "decoded = Conv2D(3, (3, 3), activation='sigmoid', padding='same')(decoded)\n",
        "\n",
        "cae = Model(input_img, decoded)\n",
        "cae.compile(optimizer='adam', loss='mse', metrics=['accuracy'])\n",
        "cae.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X1xkBnz7CVGZ",
        "outputId": "4a3924af-848b-44bb-a9aa-c160be9297b9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "800/800 [==============================] - 12s 8ms/step - loss: 0.0212 - accuracy: 0.5735 - val_loss: 0.0154 - val_accuracy: 0.6079\n",
            "Epoch 2/100\n",
            "800/800 [==============================] - 6s 7ms/step - loss: 0.0145 - accuracy: 0.6316 - val_loss: 0.0137 - val_accuracy: 0.6099\n",
            "Epoch 3/100\n",
            "800/800 [==============================] - 5s 7ms/step - loss: 0.0133 - accuracy: 0.6425 - val_loss: 0.0130 - val_accuracy: 0.6405\n",
            "Epoch 4/100\n",
            "800/800 [==============================] - 6s 8ms/step - loss: 0.0125 - accuracy: 0.6704 - val_loss: 0.0120 - val_accuracy: 0.6708\n",
            "Epoch 5/100\n",
            "800/800 [==============================] - 5s 7ms/step - loss: 0.0118 - accuracy: 0.6967 - val_loss: 0.0115 - val_accuracy: 0.7042\n",
            "Epoch 6/100\n",
            "800/800 [==============================] - 6s 8ms/step - loss: 0.0113 - accuracy: 0.7065 - val_loss: 0.0111 - val_accuracy: 0.7074\n",
            "Epoch 7/100\n",
            "800/800 [==============================] - 5s 6ms/step - loss: 0.0109 - accuracy: 0.7113 - val_loss: 0.0111 - val_accuracy: 0.7179\n",
            "Epoch 8/100\n",
            "800/800 [==============================] - 6s 7ms/step - loss: 0.0105 - accuracy: 0.7152 - val_loss: 0.0104 - val_accuracy: 0.7185\n",
            "Epoch 9/100\n",
            "800/800 [==============================] - 5s 6ms/step - loss: 0.0103 - accuracy: 0.7184 - val_loss: 0.0101 - val_accuracy: 0.7208\n",
            "Epoch 10/100\n",
            "800/800 [==============================] - 5s 7ms/step - loss: 0.0100 - accuracy: 0.7213 - val_loss: 0.0099 - val_accuracy: 0.7229\n",
            "Epoch 11/100\n",
            "800/800 [==============================] - 5s 7ms/step - loss: 0.0098 - accuracy: 0.7238 - val_loss: 0.0102 - val_accuracy: 0.6790\n",
            "Epoch 12/100\n",
            "800/800 [==============================] - 5s 6ms/step - loss: 0.0097 - accuracy: 0.7265 - val_loss: 0.0097 - val_accuracy: 0.7357\n",
            "Epoch 13/100\n",
            "800/800 [==============================] - 6s 8ms/step - loss: 0.0095 - accuracy: 0.7285 - val_loss: 0.0095 - val_accuracy: 0.7310\n",
            "Epoch 14/100\n",
            "800/800 [==============================] - 5s 6ms/step - loss: 0.0094 - accuracy: 0.7304 - val_loss: 0.0094 - val_accuracy: 0.7371\n",
            "Epoch 15/100\n",
            "800/800 [==============================] - 5s 7ms/step - loss: 0.0093 - accuracy: 0.7319 - val_loss: 0.0094 - val_accuracy: 0.7328\n",
            "Epoch 16/100\n",
            "800/800 [==============================] - 6s 8ms/step - loss: 0.0092 - accuracy: 0.7340 - val_loss: 0.0091 - val_accuracy: 0.7378\n",
            "Epoch 17/100\n",
            "800/800 [==============================] - 6s 7ms/step - loss: 0.0091 - accuracy: 0.7360 - val_loss: 0.0090 - val_accuracy: 0.7367\n",
            "Epoch 18/100\n",
            "800/800 [==============================] - 5s 6ms/step - loss: 0.0090 - accuracy: 0.7369 - val_loss: 0.0091 - val_accuracy: 0.7278\n",
            "Epoch 19/100\n",
            "800/800 [==============================] - 6s 7ms/step - loss: 0.0089 - accuracy: 0.7385 - val_loss: 0.0088 - val_accuracy: 0.7419\n",
            "Epoch 20/100\n",
            "800/800 [==============================] - 5s 7ms/step - loss: 0.0088 - accuracy: 0.7380 - val_loss: 0.0090 - val_accuracy: 0.7358\n",
            "Epoch 21/100\n",
            "800/800 [==============================] - 5s 7ms/step - loss: 0.0087 - accuracy: 0.7401 - val_loss: 0.0087 - val_accuracy: 0.7423\n",
            "Epoch 22/100\n",
            "800/800 [==============================] - 6s 7ms/step - loss: 0.0086 - accuracy: 0.7411 - val_loss: 0.0085 - val_accuracy: 0.7392\n",
            "Epoch 23/100\n",
            "800/800 [==============================] - 5s 6ms/step - loss: 0.0086 - accuracy: 0.7407 - val_loss: 0.0086 - val_accuracy: 0.7424\n",
            "Epoch 24/100\n",
            "800/800 [==============================] - 6s 7ms/step - loss: 0.0085 - accuracy: 0.7429 - val_loss: 0.0084 - val_accuracy: 0.7394\n",
            "Epoch 25/100\n",
            "800/800 [==============================] - 5s 6ms/step - loss: 0.0084 - accuracy: 0.7431 - val_loss: 0.0087 - val_accuracy: 0.7090\n",
            "Epoch 26/100\n",
            "800/800 [==============================] - 6s 7ms/step - loss: 0.0084 - accuracy: 0.7438 - val_loss: 0.0084 - val_accuracy: 0.7365\n",
            "Epoch 27/100\n",
            "800/800 [==============================] - 5s 6ms/step - loss: 0.0083 - accuracy: 0.7441 - val_loss: 0.0084 - val_accuracy: 0.7445\n",
            "Epoch 28/100\n",
            "800/800 [==============================] - 5s 7ms/step - loss: 0.0083 - accuracy: 0.7447 - val_loss: 0.0083 - val_accuracy: 0.7370\n",
            "Epoch 29/100\n",
            "800/800 [==============================] - 5s 7ms/step - loss: 0.0082 - accuracy: 0.7448 - val_loss: 0.0082 - val_accuracy: 0.7467\n",
            "Epoch 30/100\n",
            "800/800 [==============================] - 5s 6ms/step - loss: 0.0082 - accuracy: 0.7466 - val_loss: 0.0089 - val_accuracy: 0.7363\n",
            "Epoch 31/100\n",
            "800/800 [==============================] - 6s 7ms/step - loss: 0.0081 - accuracy: 0.7462 - val_loss: 0.0082 - val_accuracy: 0.7496\n",
            "Epoch 32/100\n",
            "800/800 [==============================] - 5s 6ms/step - loss: 0.0081 - accuracy: 0.7472 - val_loss: 0.0083 - val_accuracy: 0.7336\n",
            "Epoch 33/100\n",
            "800/800 [==============================] - 6s 7ms/step - loss: 0.0080 - accuracy: 0.7470 - val_loss: 0.0083 - val_accuracy: 0.7345\n",
            "Epoch 34/100\n",
            "800/800 [==============================] - 6s 7ms/step - loss: 0.0080 - accuracy: 0.7472 - val_loss: 0.0081 - val_accuracy: 0.7377\n",
            "Epoch 35/100\n",
            "800/800 [==============================] - 6s 7ms/step - loss: 0.0080 - accuracy: 0.7474 - val_loss: 0.0080 - val_accuracy: 0.7525\n",
            "Epoch 36/100\n",
            "800/800 [==============================] - 6s 7ms/step - loss: 0.0079 - accuracy: 0.7483 - val_loss: 0.0079 - val_accuracy: 0.7503\n",
            "Epoch 37/100\n",
            "800/800 [==============================] - 5s 7ms/step - loss: 0.0079 - accuracy: 0.7488 - val_loss: 0.0079 - val_accuracy: 0.7405\n",
            "Epoch 38/100\n",
            "800/800 [==============================] - 5s 6ms/step - loss: 0.0078 - accuracy: 0.7500 - val_loss: 0.0078 - val_accuracy: 0.7571\n",
            "Epoch 39/100\n",
            "800/800 [==============================] - 5s 7ms/step - loss: 0.0078 - accuracy: 0.7493 - val_loss: 0.0081 - val_accuracy: 0.7542\n",
            "Epoch 40/100\n",
            "800/800 [==============================] - 5s 7ms/step - loss: 0.0078 - accuracy: 0.7492 - val_loss: 0.0079 - val_accuracy: 0.7522\n",
            "Epoch 41/100\n",
            "800/800 [==============================] - 5s 6ms/step - loss: 0.0077 - accuracy: 0.7500 - val_loss: 0.0077 - val_accuracy: 0.7563\n",
            "Epoch 42/100\n",
            "800/800 [==============================] - 6s 7ms/step - loss: 0.0077 - accuracy: 0.7501 - val_loss: 0.0077 - val_accuracy: 0.7503\n",
            "Epoch 43/100\n",
            "800/800 [==============================] - 5s 6ms/step - loss: 0.0077 - accuracy: 0.7506 - val_loss: 0.0077 - val_accuracy: 0.7544\n",
            "Epoch 44/100\n",
            "800/800 [==============================] - 6s 7ms/step - loss: 0.0076 - accuracy: 0.7511 - val_loss: 0.0079 - val_accuracy: 0.7515\n",
            "Epoch 45/100\n",
            "800/800 [==============================] - 5s 6ms/step - loss: 0.0076 - accuracy: 0.7511 - val_loss: 0.0079 - val_accuracy: 0.7239\n",
            "Epoch 46/100\n",
            "800/800 [==============================] - 5s 7ms/step - loss: 0.0076 - accuracy: 0.7509 - val_loss: 0.0076 - val_accuracy: 0.7498\n",
            "Epoch 47/100\n",
            "800/800 [==============================] - 5s 7ms/step - loss: 0.0076 - accuracy: 0.7510 - val_loss: 0.0075 - val_accuracy: 0.7496\n",
            "Epoch 48/100\n",
            "800/800 [==============================] - 5s 6ms/step - loss: 0.0075 - accuracy: 0.7521 - val_loss: 0.0076 - val_accuracy: 0.7570\n",
            "Epoch 49/100\n",
            "800/800 [==============================] - 6s 7ms/step - loss: 0.0075 - accuracy: 0.7519 - val_loss: 0.0076 - val_accuracy: 0.7512\n",
            "Epoch 50/100\n",
            "800/800 [==============================] - 5s 6ms/step - loss: 0.0075 - accuracy: 0.7522 - val_loss: 0.0075 - val_accuracy: 0.7451\n",
            "Epoch 51/100\n",
            "800/800 [==============================] - 6s 7ms/step - loss: 0.0075 - accuracy: 0.7520 - val_loss: 0.0076 - val_accuracy: 0.7518\n",
            "Epoch 52/100\n",
            "800/800 [==============================] - 5s 6ms/step - loss: 0.0074 - accuracy: 0.7527 - val_loss: 0.0074 - val_accuracy: 0.7526\n",
            "Epoch 53/100\n",
            "800/800 [==============================] - 6s 7ms/step - loss: 0.0074 - accuracy: 0.7525 - val_loss: 0.0076 - val_accuracy: 0.7554\n",
            "Epoch 54/100\n",
            "800/800 [==============================] - 5s 6ms/step - loss: 0.0074 - accuracy: 0.7522 - val_loss: 0.0076 - val_accuracy: 0.7302\n",
            "Epoch 55/100\n",
            "800/800 [==============================] - 5s 7ms/step - loss: 0.0074 - accuracy: 0.7528 - val_loss: 0.0076 - val_accuracy: 0.7290\n",
            "Epoch 56/100\n",
            "800/800 [==============================] - 5s 6ms/step - loss: 0.0073 - accuracy: 0.7537 - val_loss: 0.0073 - val_accuracy: 0.7499\n",
            "Epoch 57/100\n",
            "800/800 [==============================] - 5s 6ms/step - loss: 0.0073 - accuracy: 0.7530 - val_loss: 0.0074 - val_accuracy: 0.7560\n",
            "Epoch 58/100\n",
            "800/800 [==============================] - 6s 7ms/step - loss: 0.0073 - accuracy: 0.7540 - val_loss: 0.0073 - val_accuracy: 0.7402\n",
            "Epoch 59/100\n",
            "800/800 [==============================] - 5s 6ms/step - loss: 0.0073 - accuracy: 0.7535 - val_loss: 0.0074 - val_accuracy: 0.7553\n",
            "Epoch 60/100\n",
            "800/800 [==============================] - 6s 7ms/step - loss: 0.0073 - accuracy: 0.7531 - val_loss: 0.0073 - val_accuracy: 0.7579\n",
            "Epoch 61/100\n",
            "800/800 [==============================] - 5s 7ms/step - loss: 0.0073 - accuracy: 0.7535 - val_loss: 0.0073 - val_accuracy: 0.7565\n",
            "Epoch 62/100\n",
            "800/800 [==============================] - 6s 7ms/step - loss: 0.0072 - accuracy: 0.7545 - val_loss: 0.0074 - val_accuracy: 0.7352\n",
            "Epoch 63/100\n",
            "800/800 [==============================] - 5s 7ms/step - loss: 0.0072 - accuracy: 0.7539 - val_loss: 0.0072 - val_accuracy: 0.7466\n",
            "Epoch 64/100\n",
            "800/800 [==============================] - 5s 7ms/step - loss: 0.0072 - accuracy: 0.7546 - val_loss: 0.0072 - val_accuracy: 0.7591\n",
            "Epoch 65/100\n",
            "800/800 [==============================] - 5s 7ms/step - loss: 0.0072 - accuracy: 0.7546 - val_loss: 0.0073 - val_accuracy: 0.7590\n",
            "Epoch 66/100\n",
            "800/800 [==============================] - 5s 6ms/step - loss: 0.0072 - accuracy: 0.7541 - val_loss: 0.0074 - val_accuracy: 0.7442\n",
            "Epoch 67/100\n",
            "800/800 [==============================] - 5s 7ms/step - loss: 0.0072 - accuracy: 0.7548 - val_loss: 0.0072 - val_accuracy: 0.7614\n",
            "Epoch 68/100\n",
            "800/800 [==============================] - 5s 6ms/step - loss: 0.0071 - accuracy: 0.7548 - val_loss: 0.0072 - val_accuracy: 0.7437\n",
            "Epoch 69/100\n",
            "800/800 [==============================] - 6s 7ms/step - loss: 0.0071 - accuracy: 0.7545 - val_loss: 0.0073 - val_accuracy: 0.7435\n",
            "Epoch 70/100\n",
            "800/800 [==============================] - 5s 6ms/step - loss: 0.0071 - accuracy: 0.7556 - val_loss: 0.0073 - val_accuracy: 0.7529\n",
            "Epoch 71/100\n",
            "800/800 [==============================] - 5s 7ms/step - loss: 0.0071 - accuracy: 0.7549 - val_loss: 0.0072 - val_accuracy: 0.7657\n",
            "Epoch 72/100\n",
            "800/800 [==============================] - 5s 6ms/step - loss: 0.0071 - accuracy: 0.7558 - val_loss: 0.0073 - val_accuracy: 0.7590\n",
            "Epoch 73/100\n",
            "800/800 [==============================] - 5s 7ms/step - loss: 0.0071 - accuracy: 0.7555 - val_loss: 0.0071 - val_accuracy: 0.7335\n",
            "Epoch 74/100\n",
            "800/800 [==============================] - 5s 7ms/step - loss: 0.0071 - accuracy: 0.7559 - val_loss: 0.0073 - val_accuracy: 0.7480\n",
            "Epoch 75/100\n",
            "800/800 [==============================] - 5s 7ms/step - loss: 0.0071 - accuracy: 0.7556 - val_loss: 0.0071 - val_accuracy: 0.7581\n",
            "Epoch 76/100\n",
            "800/800 [==============================] - 5s 7ms/step - loss: 0.0070 - accuracy: 0.7558 - val_loss: 0.0074 - val_accuracy: 0.7481\n",
            "Epoch 77/100\n",
            "800/800 [==============================] - 5s 6ms/step - loss: 0.0070 - accuracy: 0.7559 - val_loss: 0.0071 - val_accuracy: 0.7649\n",
            "Epoch 78/100\n",
            "800/800 [==============================] - 5s 7ms/step - loss: 0.0070 - accuracy: 0.7564 - val_loss: 0.0071 - val_accuracy: 0.7608\n",
            "Epoch 79/100\n",
            "800/800 [==============================] - 5s 6ms/step - loss: 0.0070 - accuracy: 0.7557 - val_loss: 0.0072 - val_accuracy: 0.7591\n",
            "Epoch 80/100\n",
            "800/800 [==============================] - 5s 7ms/step - loss: 0.0070 - accuracy: 0.7563 - val_loss: 0.0070 - val_accuracy: 0.7645\n",
            "Epoch 81/100\n",
            "800/800 [==============================] - 5s 6ms/step - loss: 0.0070 - accuracy: 0.7562 - val_loss: 0.0070 - val_accuracy: 0.7596\n",
            "Epoch 82/100\n",
            "800/800 [==============================] - 5s 6ms/step - loss: 0.0070 - accuracy: 0.7563 - val_loss: 0.0070 - val_accuracy: 0.7528\n",
            "Epoch 83/100\n",
            "800/800 [==============================] - 6s 7ms/step - loss: 0.0070 - accuracy: 0.7563 - val_loss: 0.0070 - val_accuracy: 0.7589\n",
            "Epoch 84/100\n",
            "800/800 [==============================] - 5s 6ms/step - loss: 0.0069 - accuracy: 0.7570 - val_loss: 0.0071 - val_accuracy: 0.7588\n",
            "Epoch 85/100\n",
            "800/800 [==============================] - 5s 7ms/step - loss: 0.0069 - accuracy: 0.7562 - val_loss: 0.0070 - val_accuracy: 0.7511\n",
            "Epoch 86/100\n",
            "800/800 [==============================] - 5s 6ms/step - loss: 0.0069 - accuracy: 0.7569 - val_loss: 0.0070 - val_accuracy: 0.7433\n",
            "Epoch 87/100\n",
            "800/800 [==============================] - 6s 7ms/step - loss: 0.0069 - accuracy: 0.7559 - val_loss: 0.0070 - val_accuracy: 0.7465\n",
            "Epoch 88/100\n",
            "800/800 [==============================] - 5s 6ms/step - loss: 0.0069 - accuracy: 0.7569 - val_loss: 0.0070 - val_accuracy: 0.7567\n",
            "Epoch 89/100\n",
            "800/800 [==============================] - 5s 6ms/step - loss: 0.0069 - accuracy: 0.7568 - val_loss: 0.0072 - val_accuracy: 0.7093\n",
            "Epoch 90/100\n",
            "800/800 [==============================] - 5s 7ms/step - loss: 0.0069 - accuracy: 0.7565 - val_loss: 0.0069 - val_accuracy: 0.7621\n",
            "Epoch 91/100\n",
            "800/800 [==============================] - 5s 6ms/step - loss: 0.0069 - accuracy: 0.7568 - val_loss: 0.0070 - val_accuracy: 0.7531\n",
            "Epoch 92/100\n",
            "800/800 [==============================] - 5s 7ms/step - loss: 0.0069 - accuracy: 0.7569 - val_loss: 0.0069 - val_accuracy: 0.7529\n",
            "Epoch 93/100\n",
            "800/800 [==============================] - 5s 6ms/step - loss: 0.0069 - accuracy: 0.7568 - val_loss: 0.0072 - val_accuracy: 0.7545\n",
            "Epoch 94/100\n",
            "800/800 [==============================] - 5s 7ms/step - loss: 0.0069 - accuracy: 0.7567 - val_loss: 0.0070 - val_accuracy: 0.7577\n",
            "Epoch 95/100\n",
            "800/800 [==============================] - 5s 6ms/step - loss: 0.0068 - accuracy: 0.7564 - val_loss: 0.0069 - val_accuracy: 0.7366\n",
            "Epoch 96/100\n",
            "800/800 [==============================] - 5s 7ms/step - loss: 0.0068 - accuracy: 0.7574 - val_loss: 0.0070 - val_accuracy: 0.7538\n",
            "Epoch 97/100\n",
            "800/800 [==============================] - 5s 6ms/step - loss: 0.0068 - accuracy: 0.7571 - val_loss: 0.0069 - val_accuracy: 0.7655\n",
            "Epoch 98/100\n",
            "800/800 [==============================] - 5s 6ms/step - loss: 0.0068 - accuracy: 0.7575 - val_loss: 0.0069 - val_accuracy: 0.7588\n",
            "Epoch 99/100\n",
            "800/800 [==============================] - 6s 7ms/step - loss: 0.0068 - accuracy: 0.7570 - val_loss: 0.0068 - val_accuracy: 0.7547\n",
            "Epoch 100/100\n",
            "800/800 [==============================] - 5s 6ms/step - loss: 0.0068 - accuracy: 0.7568 - val_loss: 0.0068 - val_accuracy: 0.7533\n"
          ]
        }
      ],
      "source": [
        "# Train the CAE\n",
        "early_stopping_monitor_cae = EarlyStopping(monitor='val_loss', patience=10, verbose=0, mode='min')\n",
        "cae_history = cae.fit(x_train, x_train,\n",
        "                      epochs=100,\n",
        "                      batch_size=50,\n",
        "                      validation_data=(x_val, x_val),\n",
        "                      callbacks=[early_stopping_monitor_cae])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "id": "6Juuvv8hHH18",
        "outputId": "b555e9ca-4d2a-4a4f-9b6f-9a562d27fced"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 0s 2ms/step\n",
            "Test Loss: 23.8686\n",
            "Test Accuracy: 0.1041\n",
            "313/313 [==============================] - 1s 3ms/step\n",
            "313/313 [==============================] - 1s 2ms/step\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 2000x400 with 10 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Evaluate MLP on test set\n",
        "flatten_test_np = encoder_model.predict(x_test)\n",
        "test_loss, test_accuracy = mlp.evaluate(flatten_test_np, y_test, verbose=0)\n",
        "print(f'Test Loss: {test_loss:.4f}')\n",
        "print(f'Test Accuracy: {test_accuracy:.4f}')\n",
        "\n",
        "# Show results\n",
        "decoded_data = cae.predict(x_test)\n",
        "mlp_predictions = mlp.predict(flatten_test_np)\n",
        "\n",
        "# Display some MLP predictions\n",
        "n = 10\n",
        "plt.figure(figsize=(20, 4))\n",
        "for i in range(n):\n",
        "    ax = plt.subplot(1, n, i + 1)\n",
        "    plt.imshow(x_test[i])\n",
        "    plt.title(f\"True: {y_test[i]}\\nPredicted: {np.argmax(mlp_predictions[i])}\")\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mG82PCTd0hUz"
      },
      "source": [
        "# Results ;-\n",
        "The main obstacle is the high(very) loss and very low accuracy\n",
        "## Facing this Loss MLP , our CAE is working fine."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wPkSI9joRKDh"
      },
      "source": [
        "following has better accucracy but error in representing:-\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FZJerCg51VeP"
      },
      "source": [
        "## Alternative 1:- The CAE is not explicitly defined"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EJbsRljHRKvd"
      },
      "outputs": [],
      "source": [
        "from keras.datasets import cifar10\n",
        "from keras.models import Model, Sequential\n",
        "from keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2D, Flatten, BatchNormalization, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from keras.callbacks import EarlyStopping\n",
        "import tensorflow as tf\n",
        "from keras.callbacks import EarlyStopping\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras import backend as K\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Load CIFAR-10 dataset\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "\n",
        "# Normalize and convert to float32\n",
        "x_train = x_train.astype('float32') / 255.0\n",
        "x_test = x_test.astype('float32') / 255.0\n",
        "\n",
        "# Define the input shape\n",
        "input_img = Input(shape=(32, 32, 3))\n",
        "\n",
        "# Encoder part of the CAE\n",
        "x = Conv2D(64, (3, 3), activation='relu', padding='same')(input_img)\n",
        "x = MaxPooling2D((2, 2))(x)\n",
        "x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
        "x = MaxPooling2D((2, 2))(x)\n",
        "x = Conv2D(16, (3, 3), activation='relu', padding='same')(x)\n",
        "encoded = MaxPooling2D((2, 2))(x)\n",
        "\n",
        "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=42)\n",
        "\n",
        "# ... (previous code)\n",
        "\n",
        "# Flatten the encoded output for MLP\n",
        "flatten = Flatten()(encoded)\n",
        "\n",
        "# Create a model for encoding features\n",
        "encoder_model = Model(input_img, flatten)\n",
        "\n",
        "# Obtain encoded features for training and validation sets\n",
        "flatten_train_np = encoder_model.predict(x_train)\n",
        "flatten_val_np = encoder_model.predict(x_val)\n",
        "\n",
        "# MLP for recognition\n",
        "mlp = Sequential([\n",
        "    Dense(128, activation='relu', input_shape=(flatten_train_np.shape[1],)),  # Adjust the input shape\n",
        "    Dropout(0.5),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile the MLP\n",
        "mlp.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "mlp.summary()\n",
        "\n",
        "# Train the MLP on the encoded features\n",
        "early_stopping_monitor = EarlyStopping(monitor='val_loss', patience=10, verbose=0, mode='min')\n",
        "mlp_history = mlp.fit(flatten_train_np, y_train,\n",
        "                      epochs=100,\n",
        "                      batch_size=50,\n",
        "                      validation_data=(flatten_val_np, y_val),\n",
        "                      callbacks=[early_stopping_monitor])\n",
        "\n",
        "\n",
        "# Visualize MLP training history\n",
        "plt.plot(mlp_history.history['val_loss'])\n",
        "plt.title('MLP Validation loss history')\n",
        "plt.ylabel('Loss value')\n",
        "plt.xlabel('No. epoch')\n",
        "plt.show()\n",
        "\n",
        "plt.plot(mlp_history.history['val_accuracy'])\n",
        "plt.title('MLP Validation accuracy history')\n",
        "plt.ylabel('Accuracy value')\n",
        "plt.xlabel('No. epoch')\n",
        "plt.show()\n",
        "\n",
        "# ... (previous code)\n",
        "\n",
        "# Define the CAE model (assuming cae is your autoencoder model)\n",
        "cae = Model(input_img, decoded)\n",
        "\n",
        "# Flatten the encoded output for MLP\n",
        "flatten_test_np = encoder_model.predict(x_test)\n",
        "\n",
        "# Evaluate MLP on test set\n",
        "test_loss, test_accuracy = mlp.evaluate(flatten_test_np, y_test, verbose=0)\n",
        "print(f'Test Loss: {test_loss:.4f}')\n",
        "print(f'Test Accuracy: {test_accuracy:.4f}')\n",
        "\n",
        "# Show results\n",
        "decoded_data = cae.predict(x_test)\n",
        "mlp_predictions = mlp.predict(flatten_test_np)\n",
        "\n",
        "# Display original and reconstructed images\n",
        "display_images(x_test, decoded_data)\n",
        "\n",
        "# Display some MLP predictions\n",
        "n = 10\n",
        "plt.figure(figsize=(20, 4))\n",
        "for i in range(n):\n",
        "    ax = plt.subplot(1, n, i + 1)\n",
        "    plt.imshow(x_test[i].reshape(32, 32, 3))\n",
        "    plt.title(f\"True: {y_test[i]}\\nPredicted: {np.argmax(mlp_predictions[i])}\")\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZBrDLd0VzQ7F"
      },
      "source": [
        "## Alternate 2:- The CAE is explicitly defined with a specific architecture for decoding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "IOlT-GtjzRWm",
        "outputId": "59f02983-c316-460e-ce2a-ab5636afbc65"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170498071/170498071 [==============================] - 3s 0us/step\n",
            "1250/1250 [==============================] - 15s 12ms/step\n",
            "313/313 [==============================] - 3s 10ms/step\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 128)               32896     \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 128)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 64)                8256      \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 10)                650       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 41802 (163.29 KB)\n",
            "Trainable params: 41802 (163.29 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "800/800 [==============================] - 2s 2ms/step - loss: 2.0939 - accuracy: 0.2051 - val_loss: 1.8747 - val_accuracy: 0.3075\n",
            "Epoch 2/100\n",
            "800/800 [==============================] - 2s 2ms/step - loss: 1.8995 - accuracy: 0.2837 - val_loss: 1.7832 - val_accuracy: 0.3373\n",
            "Epoch 3/100\n",
            "800/800 [==============================] - 2s 2ms/step - loss: 1.8305 - accuracy: 0.3122 - val_loss: 1.7211 - val_accuracy: 0.3708\n",
            "Epoch 4/100\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 1.7885 - accuracy: 0.3330 - val_loss: 1.6712 - val_accuracy: 0.3919\n",
            "Epoch 5/100\n",
            "800/800 [==============================] - 2s 2ms/step - loss: 1.7545 - accuracy: 0.3528 - val_loss: 1.6456 - val_accuracy: 0.4027\n",
            "Epoch 6/100\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 1.7337 - accuracy: 0.3654 - val_loss: 1.6177 - val_accuracy: 0.4112\n",
            "Epoch 7/100\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 1.7153 - accuracy: 0.3745 - val_loss: 1.6053 - val_accuracy: 0.4199\n",
            "Epoch 8/100\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 1.7032 - accuracy: 0.3796 - val_loss: 1.5873 - val_accuracy: 0.4322\n",
            "Epoch 9/100\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 1.6915 - accuracy: 0.3832 - val_loss: 1.5702 - val_accuracy: 0.4271\n",
            "Epoch 10/100\n",
            "800/800 [==============================] - 2s 2ms/step - loss: 1.6840 - accuracy: 0.3869 - val_loss: 1.5694 - val_accuracy: 0.4372\n",
            "Epoch 11/100\n",
            "800/800 [==============================] - 2s 2ms/step - loss: 1.6698 - accuracy: 0.3946 - val_loss: 1.5557 - val_accuracy: 0.4441\n",
            "Epoch 12/100\n",
            "800/800 [==============================] - 2s 2ms/step - loss: 1.6693 - accuracy: 0.3939 - val_loss: 1.5608 - val_accuracy: 0.4388\n",
            "Epoch 13/100\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 1.6577 - accuracy: 0.3971 - val_loss: 1.5481 - val_accuracy: 0.4483\n",
            "Epoch 14/100\n",
            "800/800 [==============================] - 2s 2ms/step - loss: 1.6530 - accuracy: 0.4048 - val_loss: 1.5440 - val_accuracy: 0.4429\n",
            "Epoch 15/100\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 1.6489 - accuracy: 0.4045 - val_loss: 1.5372 - val_accuracy: 0.4546\n",
            "Epoch 16/100\n",
            "800/800 [==============================] - 2s 2ms/step - loss: 1.6433 - accuracy: 0.4083 - val_loss: 1.5359 - val_accuracy: 0.4569\n",
            "Epoch 17/100\n",
            "800/800 [==============================] - 2s 2ms/step - loss: 1.6375 - accuracy: 0.4062 - val_loss: 1.5214 - val_accuracy: 0.4469\n",
            "Epoch 18/100\n",
            "800/800 [==============================] - 2s 2ms/step - loss: 1.6377 - accuracy: 0.4078 - val_loss: 1.5347 - val_accuracy: 0.4531\n",
            "Epoch 19/100\n",
            "800/800 [==============================] - 2s 2ms/step - loss: 1.6297 - accuracy: 0.4118 - val_loss: 1.5131 - val_accuracy: 0.4641\n",
            "Epoch 20/100\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 1.6277 - accuracy: 0.4126 - val_loss: 1.5238 - val_accuracy: 0.4584\n",
            "Epoch 21/100\n",
            "800/800 [==============================] - 2s 2ms/step - loss: 1.6227 - accuracy: 0.4126 - val_loss: 1.5058 - val_accuracy: 0.4643\n",
            "Epoch 22/100\n",
            "800/800 [==============================] - 2s 2ms/step - loss: 1.6190 - accuracy: 0.4139 - val_loss: 1.5024 - val_accuracy: 0.4619\n",
            "Epoch 23/100\n",
            "800/800 [==============================] - 2s 2ms/step - loss: 1.6184 - accuracy: 0.4166 - val_loss: 1.5010 - val_accuracy: 0.4638\n",
            "Epoch 24/100\n",
            "800/800 [==============================] - 2s 2ms/step - loss: 1.6110 - accuracy: 0.4194 - val_loss: 1.5059 - val_accuracy: 0.4582\n",
            "Epoch 25/100\n",
            "800/800 [==============================] - 2s 2ms/step - loss: 1.6142 - accuracy: 0.4176 - val_loss: 1.4972 - val_accuracy: 0.4691\n",
            "Epoch 26/100\n",
            "800/800 [==============================] - 2s 2ms/step - loss: 1.6105 - accuracy: 0.4192 - val_loss: 1.4979 - val_accuracy: 0.4650\n",
            "Epoch 27/100\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 1.6091 - accuracy: 0.4202 - val_loss: 1.5038 - val_accuracy: 0.4611\n",
            "Epoch 28/100\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 1.6105 - accuracy: 0.4189 - val_loss: 1.4960 - val_accuracy: 0.4608\n",
            "Epoch 29/100\n",
            "800/800 [==============================] - 2s 2ms/step - loss: 1.6024 - accuracy: 0.4213 - val_loss: 1.4955 - val_accuracy: 0.4602\n",
            "Epoch 30/100\n",
            "800/800 [==============================] - 2s 2ms/step - loss: 1.6057 - accuracy: 0.4254 - val_loss: 1.5212 - val_accuracy: 0.4584\n",
            "Epoch 31/100\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 1.6036 - accuracy: 0.4244 - val_loss: 1.4891 - val_accuracy: 0.4708\n",
            "Epoch 32/100\n",
            "800/800 [==============================] - 2s 2ms/step - loss: 1.5995 - accuracy: 0.4275 - val_loss: 1.4948 - val_accuracy: 0.4724\n",
            "Epoch 33/100\n",
            "800/800 [==============================] - 2s 2ms/step - loss: 1.5964 - accuracy: 0.4254 - val_loss: 1.4921 - val_accuracy: 0.4681\n",
            "Epoch 34/100\n",
            "800/800 [==============================] - 2s 3ms/step - loss: 1.5973 - accuracy: 0.4248 - val_loss: 1.4942 - val_accuracy: 0.4725\n",
            "Epoch 35/100\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 1.5936 - accuracy: 0.4257 - val_loss: 1.4825 - val_accuracy: 0.4714\n",
            "Epoch 36/100\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 1.5919 - accuracy: 0.4276 - val_loss: 1.4864 - val_accuracy: 0.4724\n",
            "Epoch 37/100\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 1.5950 - accuracy: 0.4275 - val_loss: 1.5002 - val_accuracy: 0.4694\n",
            "Epoch 38/100\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 1.5887 - accuracy: 0.4278 - val_loss: 1.4854 - val_accuracy: 0.4622\n",
            "Epoch 39/100\n",
            "800/800 [==============================] - 2s 2ms/step - loss: 1.5824 - accuracy: 0.4331 - val_loss: 1.4769 - val_accuracy: 0.4779\n",
            "Epoch 40/100\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 1.5854 - accuracy: 0.4311 - val_loss: 1.4827 - val_accuracy: 0.4756\n",
            "Epoch 41/100\n",
            "800/800 [==============================] - 2s 2ms/step - loss: 1.5775 - accuracy: 0.4336 - val_loss: 1.4855 - val_accuracy: 0.4727\n",
            "Epoch 42/100\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 1.5810 - accuracy: 0.4340 - val_loss: 1.4742 - val_accuracy: 0.4794\n",
            "Epoch 43/100\n",
            "800/800 [==============================] - 2s 2ms/step - loss: 1.5778 - accuracy: 0.4331 - val_loss: 1.4755 - val_accuracy: 0.4757\n",
            "Epoch 44/100\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 1.5801 - accuracy: 0.4342 - val_loss: 1.4748 - val_accuracy: 0.4828\n",
            "Epoch 45/100\n",
            "800/800 [==============================] - 2s 2ms/step - loss: 1.5779 - accuracy: 0.4357 - val_loss: 1.4707 - val_accuracy: 0.4779\n",
            "Epoch 46/100\n",
            "800/800 [==============================] - 2s 2ms/step - loss: 1.5781 - accuracy: 0.4325 - val_loss: 1.4728 - val_accuracy: 0.4744\n",
            "Epoch 47/100\n",
            "800/800 [==============================] - 2s 2ms/step - loss: 1.5779 - accuracy: 0.4340 - val_loss: 1.4727 - val_accuracy: 0.4771\n",
            "Epoch 48/100\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 1.5736 - accuracy: 0.4331 - val_loss: 1.4675 - val_accuracy: 0.4788\n",
            "Epoch 49/100\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 1.5729 - accuracy: 0.4369 - val_loss: 1.4816 - val_accuracy: 0.4717\n",
            "Epoch 50/100\n",
            "800/800 [==============================] - 2s 2ms/step - loss: 1.5723 - accuracy: 0.4373 - val_loss: 1.4661 - val_accuracy: 0.4771\n",
            "Epoch 51/100\n",
            "800/800 [==============================] - 2s 2ms/step - loss: 1.5741 - accuracy: 0.4368 - val_loss: 1.4784 - val_accuracy: 0.4807\n",
            "Epoch 52/100\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 1.5708 - accuracy: 0.4340 - val_loss: 1.4690 - val_accuracy: 0.4783\n",
            "Epoch 53/100\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 1.5667 - accuracy: 0.4377 - val_loss: 1.4777 - val_accuracy: 0.4757\n",
            "Epoch 54/100\n",
            "800/800 [==============================] - 2s 2ms/step - loss: 1.5685 - accuracy: 0.4371 - val_loss: 1.4734 - val_accuracy: 0.4713\n",
            "Epoch 55/100\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 1.5723 - accuracy: 0.4380 - val_loss: 1.4618 - val_accuracy: 0.4807\n",
            "Epoch 56/100\n",
            "800/800 [==============================] - 2s 2ms/step - loss: 1.5706 - accuracy: 0.4385 - val_loss: 1.4638 - val_accuracy: 0.4828\n",
            "Epoch 57/100\n",
            "800/800 [==============================] - 2s 2ms/step - loss: 1.5635 - accuracy: 0.4394 - val_loss: 1.4581 - val_accuracy: 0.4774\n",
            "Epoch 58/100\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 1.5622 - accuracy: 0.4406 - val_loss: 1.4622 - val_accuracy: 0.4810\n",
            "Epoch 59/100\n",
            "800/800 [==============================] - 2s 2ms/step - loss: 1.5684 - accuracy: 0.4379 - val_loss: 1.4691 - val_accuracy: 0.4790\n",
            "Epoch 60/100\n",
            "800/800 [==============================] - 4s 5ms/step - loss: 1.5606 - accuracy: 0.4397 - val_loss: 1.4578 - val_accuracy: 0.4821\n",
            "Epoch 61/100\n",
            "800/800 [==============================] - 2s 3ms/step - loss: 1.5660 - accuracy: 0.4405 - val_loss: 1.4690 - val_accuracy: 0.4810\n",
            "Epoch 62/100\n",
            "800/800 [==============================] - 2s 2ms/step - loss: 1.5621 - accuracy: 0.4390 - val_loss: 1.4542 - val_accuracy: 0.4826\n",
            "Epoch 63/100\n",
            "800/800 [==============================] - 2s 3ms/step - loss: 1.5628 - accuracy: 0.4417 - val_loss: 1.4651 - val_accuracy: 0.4755\n",
            "Epoch 64/100\n",
            "800/800 [==============================] - 2s 3ms/step - loss: 1.5657 - accuracy: 0.4419 - val_loss: 1.4541 - val_accuracy: 0.4838\n",
            "Epoch 65/100\n",
            "800/800 [==============================] - 2s 2ms/step - loss: 1.5598 - accuracy: 0.4417 - val_loss: 1.4681 - val_accuracy: 0.4825\n",
            "Epoch 66/100\n",
            "800/800 [==============================] - 2s 2ms/step - loss: 1.5658 - accuracy: 0.4397 - val_loss: 1.4534 - val_accuracy: 0.4851\n",
            "Epoch 67/100\n",
            "800/800 [==============================] - 2s 2ms/step - loss: 1.5563 - accuracy: 0.4410 - val_loss: 1.4658 - val_accuracy: 0.4778\n",
            "Epoch 68/100\n",
            "800/800 [==============================] - 2s 2ms/step - loss: 1.5555 - accuracy: 0.4428 - val_loss: 1.4552 - val_accuracy: 0.4860\n",
            "Epoch 69/100\n",
            "800/800 [==============================] - 2s 3ms/step - loss: 1.5607 - accuracy: 0.4408 - val_loss: 1.4548 - val_accuracy: 0.4805\n",
            "Epoch 70/100\n",
            "800/800 [==============================] - 2s 2ms/step - loss: 1.5544 - accuracy: 0.4420 - val_loss: 1.4586 - val_accuracy: 0.4842\n",
            "Epoch 71/100\n",
            "800/800 [==============================] - 2s 2ms/step - loss: 1.5545 - accuracy: 0.4430 - val_loss: 1.4612 - val_accuracy: 0.4807\n",
            "Epoch 72/100\n",
            "800/800 [==============================] - 2s 3ms/step - loss: 1.5588 - accuracy: 0.4413 - val_loss: 1.4618 - val_accuracy: 0.4821\n",
            "Epoch 73/100\n",
            "800/800 [==============================] - 2s 3ms/step - loss: 1.5626 - accuracy: 0.4392 - val_loss: 1.4586 - val_accuracy: 0.4843\n",
            "Epoch 74/100\n",
            "800/800 [==============================] - 2s 2ms/step - loss: 1.5534 - accuracy: 0.4458 - val_loss: 1.4589 - val_accuracy: 0.4769\n",
            "Epoch 75/100\n",
            "800/800 [==============================] - 2s 2ms/step - loss: 1.5565 - accuracy: 0.4414 - val_loss: 1.4539 - val_accuracy: 0.4893\n",
            "Epoch 76/100\n",
            "800/800 [==============================] - 2s 2ms/step - loss: 1.5577 - accuracy: 0.4431 - val_loss: 1.4511 - val_accuracy: 0.4804\n",
            "Epoch 77/100\n",
            "800/800 [==============================] - 2s 2ms/step - loss: 1.5595 - accuracy: 0.4404 - val_loss: 1.4523 - val_accuracy: 0.4865\n",
            "Epoch 78/100\n",
            "800/800 [==============================] - 2s 2ms/step - loss: 1.5501 - accuracy: 0.4444 - val_loss: 1.4481 - val_accuracy: 0.4873\n",
            "Epoch 79/100\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 1.5589 - accuracy: 0.4410 - val_loss: 1.4547 - val_accuracy: 0.4855\n",
            "Epoch 80/100\n",
            "800/800 [==============================] - 2s 2ms/step - loss: 1.5531 - accuracy: 0.4450 - val_loss: 1.4542 - val_accuracy: 0.4892\n",
            "Epoch 81/100\n",
            "800/800 [==============================] - 2s 2ms/step - loss: 1.5576 - accuracy: 0.4416 - val_loss: 1.4564 - val_accuracy: 0.4831\n",
            "Epoch 82/100\n",
            "800/800 [==============================] - 2s 3ms/step - loss: 1.5545 - accuracy: 0.4433 - val_loss: 1.4522 - val_accuracy: 0.4865\n",
            "Epoch 83/100\n",
            "800/800 [==============================] - 2s 3ms/step - loss: 1.5495 - accuracy: 0.4459 - val_loss: 1.4537 - val_accuracy: 0.4892\n",
            "Epoch 84/100\n",
            "800/800 [==============================] - 2s 3ms/step - loss: 1.5483 - accuracy: 0.4478 - val_loss: 1.4499 - val_accuracy: 0.4873\n",
            "Epoch 85/100\n",
            "800/800 [==============================] - 2s 3ms/step - loss: 1.5490 - accuracy: 0.4456 - val_loss: 1.4466 - val_accuracy: 0.4849\n",
            "Epoch 86/100\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 1.5482 - accuracy: 0.4460 - val_loss: 1.4410 - val_accuracy: 0.4888\n",
            "Epoch 87/100\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 1.5457 - accuracy: 0.4478 - val_loss: 1.4454 - val_accuracy: 0.4864\n",
            "Epoch 88/100\n",
            "800/800 [==============================] - 2s 2ms/step - loss: 1.5473 - accuracy: 0.4475 - val_loss: 1.4497 - val_accuracy: 0.4837\n",
            "Epoch 89/100\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 1.5489 - accuracy: 0.4463 - val_loss: 1.4423 - val_accuracy: 0.4875\n",
            "Epoch 90/100\n",
            "800/800 [==============================] - 2s 2ms/step - loss: 1.5419 - accuracy: 0.4480 - val_loss: 1.4444 - val_accuracy: 0.4881\n",
            "Epoch 91/100\n",
            "800/800 [==============================] - 2s 2ms/step - loss: 1.5448 - accuracy: 0.4478 - val_loss: 1.4587 - val_accuracy: 0.4778\n",
            "Epoch 92/100\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 1.5459 - accuracy: 0.4467 - val_loss: 1.4541 - val_accuracy: 0.4838\n",
            "Epoch 93/100\n",
            "800/800 [==============================] - 2s 2ms/step - loss: 1.5433 - accuracy: 0.4487 - val_loss: 1.4523 - val_accuracy: 0.4877\n",
            "Epoch 94/100\n",
            "800/800 [==============================] - 1s 2ms/step - loss: 1.5401 - accuracy: 0.4510 - val_loss: 1.4448 - val_accuracy: 0.4901\n",
            "Epoch 95/100\n",
            "800/800 [==============================] - 2s 2ms/step - loss: 1.5387 - accuracy: 0.4512 - val_loss: 1.4520 - val_accuracy: 0.4833\n",
            "Epoch 96/100\n",
            "800/800 [==============================] - 2s 2ms/step - loss: 1.5412 - accuracy: 0.4508 - val_loss: 1.4485 - val_accuracy: 0.4856\n",
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 32, 32, 64)        1792      \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 16, 16, 64)        0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 16, 16, 32)        18464     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPoolin  (None, 8, 8, 32)          0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 8, 8, 16)          4624      \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPoolin  (None, 4, 4, 16)          0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 256)               0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 256)               65792     \n",
            "                                                                 \n",
            " reshape (Reshape)           (None, 4, 4, 16)          0         \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 4, 4, 16)          2320      \n",
            "                                                                 \n",
            " up_sampling2d (UpSampling2  (None, 8, 8, 16)          0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 8, 8, 32)          4640      \n",
            "                                                                 \n",
            " up_sampling2d_1 (UpSamplin  (None, 16, 16, 32)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 16, 16, 64)        18496     \n",
            "                                                                 \n",
            " up_sampling2d_2 (UpSamplin  (None, 32, 32, 64)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_6 (Conv2D)           (None, 32, 32, 3)         1731      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 117859 (460.39 KB)\n",
            "Trainable params: 117859 (460.39 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "800/800 [==============================] - 138s 172ms/step - loss: 0.0214 - accuracy: 0.5718 - val_loss: 0.0162 - val_accuracy: 0.6310\n",
            "Epoch 2/100\n",
            "800/800 [==============================] - 138s 172ms/step - loss: 0.0144 - accuracy: 0.6296 - val_loss: 0.0138 - val_accuracy: 0.6431\n",
            "Epoch 3/100\n",
            "800/800 [==============================] - 122s 153ms/step - loss: 0.0130 - accuracy: 0.6454 - val_loss: 0.0125 - val_accuracy: 0.6610\n",
            "Epoch 4/100\n",
            "800/800 [==============================] - 127s 159ms/step - loss: 0.0121 - accuracy: 0.6858 - val_loss: 0.0130 - val_accuracy: 0.6953\n",
            "Epoch 5/100\n",
            "800/800 [==============================] - 126s 158ms/step - loss: 0.0115 - accuracy: 0.7010 - val_loss: 0.0112 - val_accuracy: 0.6914\n",
            "Epoch 6/100\n",
            "800/800 [==============================] - 124s 155ms/step - loss: 0.0110 - accuracy: 0.7092 - val_loss: 0.0107 - val_accuracy: 0.7169\n",
            "Epoch 7/100\n",
            "800/800 [==============================] - 120s 150ms/step - loss: 0.0107 - accuracy: 0.7140 - val_loss: 0.0108 - val_accuracy: 0.7075\n",
            "Epoch 8/100\n",
            "800/800 [==============================] - 120s 150ms/step - loss: 0.0104 - accuracy: 0.7186 - val_loss: 0.0102 - val_accuracy: 0.7268\n",
            "Epoch 9/100\n",
            "800/800 [==============================] - 120s 150ms/step - loss: 0.0102 - accuracy: 0.7216 - val_loss: 0.0101 - val_accuracy: 0.7164\n",
            "Epoch 10/100\n",
            "800/800 [==============================] - 120s 150ms/step - loss: 0.0099 - accuracy: 0.7263 - val_loss: 0.0099 - val_accuracy: 0.7112\n",
            "Epoch 11/100\n",
            "800/800 [==============================] - 120s 150ms/step - loss: 0.0097 - accuracy: 0.7276 - val_loss: 0.0096 - val_accuracy: 0.7313\n",
            "Epoch 12/100\n",
            "800/800 [==============================] - 120s 150ms/step - loss: 0.0096 - accuracy: 0.7309 - val_loss: 0.0095 - val_accuracy: 0.7363\n",
            "Epoch 13/100\n",
            "800/800 [==============================] - 120s 150ms/step - loss: 0.0094 - accuracy: 0.7330 - val_loss: 0.0093 - val_accuracy: 0.7383\n",
            "Epoch 14/100\n",
            "800/800 [==============================] - 120s 150ms/step - loss: 0.0093 - accuracy: 0.7331 - val_loss: 0.0092 - val_accuracy: 0.7113\n",
            "Epoch 15/100\n",
            "800/800 [==============================] - 120s 150ms/step - loss: 0.0092 - accuracy: 0.7352 - val_loss: 0.0092 - val_accuracy: 0.7387\n",
            "Epoch 16/100\n",
            "800/800 [==============================] - 121s 152ms/step - loss: 0.0090 - accuracy: 0.7374 - val_loss: 0.0090 - val_accuracy: 0.7435\n",
            "Epoch 17/100\n",
            "800/800 [==============================] - 119s 149ms/step - loss: 0.0089 - accuracy: 0.7378 - val_loss: 0.0091 - val_accuracy: 0.7454\n",
            "Epoch 18/100\n",
            "800/800 [==============================] - 120s 150ms/step - loss: 0.0089 - accuracy: 0.7389 - val_loss: 0.0088 - val_accuracy: 0.7455\n",
            "Epoch 19/100\n",
            "800/800 [==============================] - 120s 150ms/step - loss: 0.0087 - accuracy: 0.7407 - val_loss: 0.0089 - val_accuracy: 0.7410\n",
            "Epoch 20/100\n",
            "800/800 [==============================] - 119s 149ms/step - loss: 0.0087 - accuracy: 0.7407 - val_loss: 0.0087 - val_accuracy: 0.7500\n",
            "Epoch 21/100\n",
            "800/800 [==============================] - 119s 148ms/step - loss: 0.0086 - accuracy: 0.7421 - val_loss: 0.0085 - val_accuracy: 0.7274\n",
            "Epoch 22/100\n",
            "800/800 [==============================] - 118s 148ms/step - loss: 0.0085 - accuracy: 0.7435 - val_loss: 0.0090 - val_accuracy: 0.7112\n",
            "Epoch 23/100\n",
            "800/800 [==============================] - 119s 149ms/step - loss: 0.0084 - accuracy: 0.7440 - val_loss: 0.0086 - val_accuracy: 0.7496\n",
            "Epoch 24/100\n",
            "800/800 [==============================] - 122s 152ms/step - loss: 0.0084 - accuracy: 0.7441 - val_loss: 0.0083 - val_accuracy: 0.7437\n",
            "Epoch 25/100\n",
            "800/800 [==============================] - 122s 153ms/step - loss: 0.0083 - accuracy: 0.7454 - val_loss: 0.0082 - val_accuracy: 0.7435\n",
            "Epoch 26/100\n",
            "800/800 [==============================] - 122s 153ms/step - loss: 0.0083 - accuracy: 0.7458 - val_loss: 0.0083 - val_accuracy: 0.7423\n",
            "Epoch 27/100\n",
            "800/800 [==============================] - 119s 149ms/step - loss: 0.0082 - accuracy: 0.7463 - val_loss: 0.0082 - val_accuracy: 0.7554\n",
            "Epoch 28/100\n",
            "800/800 [==============================] - 122s 153ms/step - loss: 0.0082 - accuracy: 0.7469 - val_loss: 0.0082 - val_accuracy: 0.7496\n",
            "Epoch 29/100\n",
            "800/800 [==============================] - 119s 149ms/step - loss: 0.0081 - accuracy: 0.7472 - val_loss: 0.0081 - val_accuracy: 0.7385\n",
            "Epoch 30/100\n",
            "800/800 [==============================] - 119s 149ms/step - loss: 0.0081 - accuracy: 0.7478 - val_loss: 0.0082 - val_accuracy: 0.7445\n",
            "Epoch 31/100\n",
            "800/800 [==============================] - 119s 148ms/step - loss: 0.0080 - accuracy: 0.7486 - val_loss: 0.0081 - val_accuracy: 0.7343\n",
            "Epoch 32/100\n",
            "800/800 [==============================] - 119s 149ms/step - loss: 0.0080 - accuracy: 0.7485 - val_loss: 0.0080 - val_accuracy: 0.7574\n",
            "Epoch 33/100\n",
            "800/800 [==============================] - 118s 147ms/step - loss: 0.0079 - accuracy: 0.7488 - val_loss: 0.0080 - val_accuracy: 0.7494\n",
            "Epoch 34/100\n",
            "800/800 [==============================] - 119s 149ms/step - loss: 0.0079 - accuracy: 0.7494 - val_loss: 0.0079 - val_accuracy: 0.7436\n",
            "Epoch 35/100\n",
            "800/800 [==============================] - 122s 153ms/step - loss: 0.0079 - accuracy: 0.7492 - val_loss: 0.0080 - val_accuracy: 0.7231\n",
            "Epoch 36/100\n",
            "800/800 [==============================] - 118s 147ms/step - loss: 0.0078 - accuracy: 0.7504 - val_loss: 0.0078 - val_accuracy: 0.7535\n",
            "Epoch 37/100\n",
            "800/800 [==============================] - 120s 151ms/step - loss: 0.0078 - accuracy: 0.7497 - val_loss: 0.0083 - val_accuracy: 0.7376\n",
            "Epoch 38/100\n",
            "800/800 [==============================] - 126s 158ms/step - loss: 0.0077 - accuracy: 0.7501 - val_loss: 0.0078 - val_accuracy: 0.7515\n",
            "Epoch 39/100\n",
            "800/800 [==============================] - 124s 155ms/step - loss: 0.0077 - accuracy: 0.7509 - val_loss: 0.0077 - val_accuracy: 0.7473\n",
            "Epoch 40/100\n",
            "800/800 [==============================] - 124s 155ms/step - loss: 0.0077 - accuracy: 0.7508 - val_loss: 0.0078 - val_accuracy: 0.7561\n",
            "Epoch 41/100\n",
            "800/800 [==============================] - 125s 156ms/step - loss: 0.0076 - accuracy: 0.7502 - val_loss: 0.0076 - val_accuracy: 0.7521\n",
            "Epoch 42/100\n",
            "800/800 [==============================] - 120s 149ms/step - loss: 0.0076 - accuracy: 0.7513 - val_loss: 0.0076 - val_accuracy: 0.7438\n",
            "Epoch 43/100\n",
            "800/800 [==============================] - 120s 151ms/step - loss: 0.0076 - accuracy: 0.7507 - val_loss: 0.0077 - val_accuracy: 0.7541\n",
            "Epoch 44/100\n",
            "800/800 [==============================] - 120s 150ms/step - loss: 0.0075 - accuracy: 0.7515 - val_loss: 0.0076 - val_accuracy: 0.7543\n",
            "Epoch 45/100\n",
            "800/800 [==============================] - 120s 150ms/step - loss: 0.0075 - accuracy: 0.7518 - val_loss: 0.0077 - val_accuracy: 0.7522\n",
            "Epoch 46/100\n",
            "800/800 [==============================] - 121s 151ms/step - loss: 0.0075 - accuracy: 0.7520 - val_loss: 0.0075 - val_accuracy: 0.7545\n",
            "Epoch 47/100\n",
            "800/800 [==============================] - 125s 156ms/step - loss: 0.0074 - accuracy: 0.7514 - val_loss: 0.0075 - val_accuracy: 0.7472\n",
            "Epoch 48/100\n",
            "800/800 [==============================] - 120s 151ms/step - loss: 0.0074 - accuracy: 0.7529 - val_loss: 0.0078 - val_accuracy: 0.7393\n",
            "Epoch 49/100\n",
            "800/800 [==============================] - 120s 150ms/step - loss: 0.0074 - accuracy: 0.7516 - val_loss: 0.0074 - val_accuracy: 0.7561\n",
            "Epoch 50/100\n",
            "800/800 [==============================] - 121s 151ms/step - loss: 0.0074 - accuracy: 0.7523 - val_loss: 0.0075 - val_accuracy: 0.7515\n",
            "Epoch 51/100\n",
            "800/800 [==============================] - 120s 150ms/step - loss: 0.0073 - accuracy: 0.7527 - val_loss: 0.0073 - val_accuracy: 0.7513\n",
            "Epoch 52/100\n",
            "800/800 [==============================] - 121s 151ms/step - loss: 0.0073 - accuracy: 0.7522 - val_loss: 0.0072 - val_accuracy: 0.7446\n",
            "Epoch 53/100\n",
            "800/800 [==============================] - 125s 156ms/step - loss: 0.0073 - accuracy: 0.7529 - val_loss: 0.0074 - val_accuracy: 0.7541\n",
            "Epoch 54/100\n",
            "800/800 [==============================] - 123s 154ms/step - loss: 0.0073 - accuracy: 0.7533 - val_loss: 0.0073 - val_accuracy: 0.7503\n",
            "Epoch 55/100\n",
            "800/800 [==============================] - 126s 158ms/step - loss: 0.0073 - accuracy: 0.7535 - val_loss: 0.0073 - val_accuracy: 0.7627\n",
            "Epoch 56/100\n",
            "800/800 [==============================] - 130s 162ms/step - loss: 0.0072 - accuracy: 0.7530 - val_loss: 0.0072 - val_accuracy: 0.7478\n",
            "Epoch 57/100\n",
            "800/800 [==============================] - 129s 161ms/step - loss: 0.0072 - accuracy: 0.7532 - val_loss: 0.0073 - val_accuracy: 0.7585\n",
            "Epoch 58/100\n",
            "800/800 [==============================] - 125s 157ms/step - loss: 0.0072 - accuracy: 0.7540 - val_loss: 0.0072 - val_accuracy: 0.7481\n",
            "Epoch 59/100\n",
            "800/800 [==============================] - 124s 155ms/step - loss: 0.0072 - accuracy: 0.7538 - val_loss: 0.0072 - val_accuracy: 0.7568\n",
            "Epoch 60/100\n",
            "800/800 [==============================] - 122s 153ms/step - loss: 0.0071 - accuracy: 0.7539 - val_loss: 0.0072 - val_accuracy: 0.7579\n",
            "Epoch 61/100\n",
            "800/800 [==============================] - 121s 151ms/step - loss: 0.0071 - accuracy: 0.7548 - val_loss: 0.0072 - val_accuracy: 0.7635\n",
            "Epoch 62/100\n",
            "  1/800 [..............................] - ETA: 1:52 - loss: 0.0069 - accuracy: 0.7563"
          ]
        }
      ],
      "source": [
        "from keras.datasets import cifar10\n",
        "from keras.models import Model, Sequential\n",
        "from keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2D, Flatten, BatchNormalization, Dropout, Reshape\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from keras.callbacks import EarlyStopping\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load CIFAR-10 dataset\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "\n",
        "# Normalize and convert to float32\n",
        "x_train = x_train.astype('float32') / 255.0\n",
        "x_test = x_test.astype('float32') / 255.0\n",
        "\n",
        "# Define the input shape\n",
        "input_img = Input(shape=(32, 32, 3))\n",
        "\n",
        "# Encoder part of the CAE\n",
        "x = Conv2D(64, (3, 3), activation='relu', padding='same')(input_img)\n",
        "x = MaxPooling2D((2, 2))(x)\n",
        "x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
        "x = MaxPooling2D((2, 2))(x)\n",
        "x = Conv2D(16, (3, 3), activation='relu', padding='same')(x)\n",
        "encoded = MaxPooling2D((2, 2))(x)\n",
        "\n",
        "# Flatten the encoded output for MLP\n",
        "flatten = Flatten()(encoded)\n",
        "\n",
        "# Create a model for encoding features\n",
        "encoder_model = Model(input_img, flatten)\n",
        "\n",
        "# Obtain encoded features for training and validation sets\n",
        "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=42)\n",
        "flatten_train_np = encoder_model.predict(x_train)\n",
        "flatten_val_np = encoder_model.predict(x_val)\n",
        "\n",
        "# MLP for recognition with 400 neurons in the second layer\n",
        "mlp = Sequential([\n",
        "    Dense(128, activation='relu', input_shape=(flatten_train_np.shape[1],)),\n",
        "    Dropout(0.5),\n",
        "    Dense(400, activation='relu'),  # Updated to have 400 neurons\n",
        "    Dropout(0.5),\n",
        "    Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile the MLP\n",
        "mlp.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "mlp.summary()\n",
        "\n",
        "# Train the MLP on the encoded features\n",
        "early_stopping_monitor = EarlyStopping(monitor='val_loss', patience=10, verbose=0, mode='min')\n",
        "mlp_history = mlp.fit(flatten_train_np, y_train,\n",
        "                      epochs=100,\n",
        "                      batch_size=50,\n",
        "                      validation_data=(flatten_val_np, y_val),\n",
        "                      callbacks=[early_stopping_monitor])\n",
        "\n",
        "# Define the CAE model\n",
        "decoded = Dense(256, activation='relu')(flatten)\n",
        "decoded = Reshape((4, 4, 16))(decoded)\n",
        "decoded = Conv2D(16, (3, 3), activation='relu', padding='same')(decoded)\n",
        "decoded = UpSampling2D((2, 2))(decoded)\n",
        "decoded = Conv2D(32, (3, 3), activation='relu', padding='same')(decoded)\n",
        "decoded = UpSampling2D((2, 2))(decoded)\n",
        "decoded = Conv2D(64, (3, 3), activation='relu', padding='same')(decoded)\n",
        "decoded = UpSampling2D((2, 2))(decoded)\n",
        "decoded = Conv2D(3, (3, 3), activation='sigmoid', padding='same')(decoded)\n",
        "\n",
        "cae = Model(input_img, decoded)\n",
        "cae.compile(optimizer='adam', loss='mse', metrics=['accuracy'])\n",
        "cae.summary()\n",
        "\n",
        "# Train the CAE\n",
        "early_stopping_monitor_cae = EarlyStopping(monitor='val_loss', patience=10, verbose=0, mode='min')\n",
        "cae_history = cae.fit(x_train, x_train,\n",
        "                      epochs=100,\n",
        "                      batch_size=50,\n",
        "                      validation_data=(x_val, x_val),\n",
        "                      callbacks=[early_stopping_monitor_cae])\n",
        "\n",
        "# Evaluate MLP on test set\n",
        "flatten_test_np = encoder_model.predict(x_test)\n",
        "test_loss, test_accuracy = mlp.evaluate(flatten_test_np, y_test, verbose=0)\n",
        "print(f'MLP Test Loss: {test_loss:.4f}')\n",
        "print(f'MLP Test Accuracy: {test_accuracy:.4f}')\n",
        "\n",
        "# Evaluate CAE on test set\n",
        "cae_test_loss, cae_test_accuracy = cae.evaluate(x_test, x_test, verbose=0)\n",
        "print(f'CAE Test Loss: {cae_test_loss:.4f}')\n",
        "print(f'CAE Test Accuracy: {cae_test_accuracy:.4f}')\n",
        "\n",
        "# Show results\n",
        "decoded_data = cae.predict(x_test)\n",
        "mlp_predictions = mlp.predict(flatten_test_np)\n",
        "\n",
        "# Display some MLP predictions\n",
        "n = 10\n",
        "plt.figure(figsize=(20, 4))\n",
        "for i in range(n):\n",
        "    ax = plt.subplot(1, n, i + 1)\n",
        "    plt.imshow(x_test[i])\n",
        "    plt.title(f\"True: {y_test[i]}\\nPredicted: {np.argmax(mlp_predictions[i])}\")\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New approach - BEST approach yet\n"
      ],
      "metadata": {
        "id": "lhxC_Uqmm6no"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.datasets import cifar10\n",
        "from keras.models import Model, Sequential\n",
        "from keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2D, Flatten, BatchNormalization, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from keras.callbacks import EarlyStopping\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "9jUlB-1ZnHqf"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Load CIFAR-10 dataset\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bm64qvYXnJd1",
        "outputId": "99383293-6f04-4a8d-a739-f64742dba003"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170498071/170498071 [==============================] - 8s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Normalize and convert to float32\n",
        "x_train = x_train.astype('float32') / 255.0\n",
        "x_test = x_test.astype('float32') / 255.0\n",
        "\n",
        "# Define the input shape\n",
        "input_img = Input(shape=(32, 32, 3))\n",
        "\n",
        "# Encoder part of the CAE\n",
        "x = Conv2D(64, (3, 3), activation='relu', padding='same')(input_img)\n",
        "x = MaxPooling2D((2, 2))(x)\n",
        "x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
        "x = MaxPooling2D((2, 2))(x)\n",
        "x = Conv2D(16, (3, 3), activation='relu', padding='same')(x)\n",
        "encoded = MaxPooling2D((2, 2))(x)\n",
        "\n",
        "# Flatten the encoded output for MLP\n",
        "flatten = Flatten()(encoded)\n",
        "\n",
        "# Create a model for encoding features\n",
        "encoder_model = Model(input_img, flatten)\n",
        "\n",
        "# Obtain encoded features for training and validation sets\n",
        "flatten_train_np = encoder_model.predict(x_train)\n",
        "flatten_test_np = encoder_model.predict(x_test)\n",
        "\n",
        "# MLP for recognition\n",
        "mlp = Sequential([\n",
        "    Dense(400, activation='relu', input_shape=(flatten_train_np.shape[1],)),\n",
        "    Dropout(0.5),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile the MLP\n",
        "mlp.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "mlp.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8DBQ3TQCnOnp",
        "outputId": "e164b78c-e4f0-49eb-9dfe-d89bdd2a3929"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 511/1563 [========>.....................] - ETA: 17s"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Train the MLP on the encoded features\n",
        "x_train, x_val, y_train, y_val = train_test_split(flatten_train_np, y_train, test_size=0.2, random_state=42)\n",
        "\n",
        "early_stopping_monitor = EarlyStopping(monitor='val_loss', patience=10, verbose=0, mode='min')\n",
        "mlp_history = mlp.fit(x_train, y_train,\n",
        "                      epochs=100,\n",
        "                      batch_size=50,\n",
        "                      validation_data=(x_val, y_val),\n",
        "                      callbacks=[early_stopping_monitor])\n"
      ],
      "metadata": {
        "id": "E7at8PegnTe_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Visualize MLP training history\n",
        "plt.plot(mlp_history.history['val_loss'])\n",
        "plt.title('MLP Validation loss history')\n",
        "plt.ylabel('Loss value')\n",
        "plt.xlabel('No. epoch')\n",
        "plt.show()\n",
        "\n",
        "plt.plot(mlp_history.history['val_accuracy'])\n",
        "plt.title('MLP Validation accuracy history')\n",
        "plt.ylabel('Accuracy value')\n",
        "plt.xlabel('No. epoch')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "uJInV3jPnW4_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Evaluate MLP on test set\n",
        "test_loss, test_accuracy = mlp.evaluate(flatten_test_np, y_test, verbose=0)\n",
        "print(f'Test Loss: {test_loss:.4f}')\n",
        "print(f'Test Accuracy: {test_accuracy:.4f}')\n",
        "\n"
      ],
      "metadata": {
        "id": "spjb2u7Nm9ri"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}